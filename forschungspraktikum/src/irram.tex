\chapter{iRRAM}
Die Software-Bibliothek \verb+iRRAM+ \cite{Mller2009EnhancingIE} basiert auf Intervallen als Zahlentyp, um diese mit einer beliebigen Genauigkeit darstellen zu können. Zunächst wird mit Double-Präzision (64-Bit Zahlen) gerechnet, welche verwendet werden, bis das Ergebnis für die angefragte Präzision nicht mehr genau ausgegeben werden kann, beziehungsweise bis zu einer bestimmten Anzahl an Bits. Ist dies der Fall, geschieht eine Iteration mit einer erhöhten Genauigkeit, also längeren Zahlen, welche dann mit Hilfe von \verb+MPFR+ dargestellt werden.
Für eine solche Iteration werden gerade so viele Zwischenergebnisse während der Berechnung gespeichert, dass eine Wiederholung der Schritte mit höherer Präzision möglich ist. Da nicht die gesamte Berechnung in jeder Iteration wiederholt wird, müssen während der Laufzeit Sichtbarkeit von Variablen und Zwischenergebnisse für den Nutzer genau kontrolliert und unter Umständen beschränkt werden, da sonst unerwartetes Verhalten und Exceptions entstehen können, indem die zugegriffenen Werte gegebenfall nicht in der aktuellen Iteration existieren.

\section{Verwendung der iRRAM-REALs}
Einige der für rationale Zahlen zur Verfügung stehenden Funktionen, wie der Vergleich zweier Zahlen, sind mit reellen Zahlen nicht ohne Weiteres Möglich. Dies gilt insbesondere für den Test auf Gleichheit und die Vorzeichenfunktion $sign$. Bei all diesen Funktionen handelt es sich im Reellen (und bei der \verb+iRRAM+) um mehrwertige Funktionen, da sich das jeweilige Ergebnis mit veränderter Präzsion in der Darstellung der Zahlen ändern kann. Dieses Problem wird in \verb+hotm+ durch den \verb+SignType+ adressiert. Zusätzlich zu den Werten 'positiv' (=\verb+POS+) und 'negativ' (=\verb+NEG+),  kann die Vorzeichenfunktion \verb+sign+ den Wert 'ambivalent' (=\verb+AMBI+) ausgeben, wenn nicht entscheidbar ist, wo genau die reelle Zahl um die Null liegt. Hierfür erhält die Vorzeichenfunktion einen Parameter, der den Bereich er Unsicherheit definiert. Ist der Ausgabewert 'ambivalent', so wird in den Funktionen, welche die Vorzeichenfunktion aufrufen, der schlechteste Fall im Hinblick auf die Genauigkeit des Ergebnisses angenommen. 


Eine weitere Besonderheit ergibt sich aus dem Aufbau der Zahlen, denn es entstehen zwei Intervall-`Ebenen`: Zum Einen, die Darstellung des Koeffizienten als Intervall aus Mitte und Radius. Zum Anderen die Darstellung von Mitte und Radius, als \verb+iRRAM-REAL+, also auch wiederum jeweils als Intervall mit Wert und Fehler, wie in Grafik \ref{fig:levels} zu sehen ist. Im Vergleich zu den \verb+mpq-RATIONALS+ erhöht sich hier zwar die Komplexität deutlich, allerdings lassen sich Ungenauigkeiten sehr genau steuern, indem zum Beispiel der Rechenfehler des Mittelpunkts eines Koeffizienten auf den Radius 'verlagert' wird. So vergrößert sich zwar der Radius des Koeffizienten, welcher dadurch ungenauer wird, jedoch verkleinert sich der Rechenfehler auf der Zahlenebene der \verb+REAL+s. Ein ählicher Effekt sollte sich durch Rundung auch mit den \verb+mpq-RATIONALS+ erreichen lassen. 


Das Verlagern der Ungenauigkeit ($e$ in der Grafik \ref{fig:levels}) auf den Wert des Radius' ($v$ in der Grafik), \textit{Micro-Housekeeping} genannt, verringert die Intervallbreite und erzeugt Punktintervalle auf der Zahlenebene, allerdings werden die Intervalle auf der Intervallebene breiter. Hier greift dann wiederum der Polish-Mechanismus, der auf Polynomebene Monome hinzufügt, um aus den zu groß gewordenen Intervallen wiederum Punktintervalle zu machen, \textit{Macro-Housekeeping} genannt. So wird der Rechenfehler von der untersten Ebene bis zur Polynomebene propagiert.
Diese Housekeeping-Funktionen werden durch Parameter gesteuert, die bestimmen, ab wann ein Intervall zu breit ist und die jeweilige Prozedur angewandt werden soll.

\begin{figure}[ht]
\label{fig:levels}
\begin{center}
 
 \input{graphs/levels.tex}
 \caption{Ebenen der Polynomdarstellung mit REALs (informell)}
 \end{center}
\end{figure}


\section{Genauigkeitsmodell}
Die \verb+iRRAM+ bietet die Möglichkeit, zwischen \textit{absoluter} und \textit{relativer} Genauigkeit zu unterscheiden. Absolute Genauigkeit bedeutet, dass beim Verrechnen zweier \verb+REAL+s ein global verwendeter Wert für die Genauigkeit zugrunde liegt und die Zahlen dementsprechen skaliert werden. Bei relativer Genauigkeit hängt die verwendete Genauigkeit von der tatsächlichen Größe der jeweiligen Zahlen ab. Diese kann zum Beispiel durch punktuelle Anwendung von Micro-Housekeeping stark variieren, weshalb die Verwendung von relativer Genauigkeit in der Praxis besser funktioniert.


Für der Vergleich wurde $x_{1000}$ mit $x_n = c \cdot x_{n-1} \cdot (1 - x_{n-1})$ mit der folgenden Konfiguration berechnet:
\begin{enumerate}
 \item Nur quadratisches Sweeping zur 0,
 \item Micro-Housekeeping (Cleaning) ab einem Fehler auf Zahlenebene $>10^{-100}$,
 \item Macro-Housekeeping (Polish) ab einer Intervallbreite $>10^{-50}$,
 \item $x_0 = 0,5$ und
 \item Ausgabe des Ergebnisses auf 20 Stellen genau.
\end{enumerate}
Zu Beginn einer jeden Iteration wird zunächst gesweept (1.), dann der Fehler und die Intervalle bereinigt (2.) und zuletzt das Polynom poliert (3.), bevor erneut multipliziert wird. Für $c = 3.25$ konvergiert die Funktion gegen zwei Werte und lässt sich sehr genau bestimmen.

\begin{center}
\begin{tabular}{|r|c|c|}
\hline
\multicolumn{3}{|c|}{$c=3.25$}\\
\hline
 ohne Housekeeping&relative Genauigkeit & absolute Genauigkeit \\
 \hline
 \hline
 Anzahl Polishs & 142 & 6961 \\
 Präzision (Bits) & \verb+double+ & 136 \\
 CPU-Zeit & 0.8s & 4.43s\\
 \hline
\end{tabular}
\end{center}

Wie in der Tabelle zu sehen ist, benötigt die Berechnung mit relativer Genauigkeit erheblich weniger Zeit und Bits um ein Ergebnis mit der geforderten Auflösung zu erhalten. Wird auf die Housekeeping-Methoden verzichtet, zeigt sich dieser massive Unterschied jedoch nicht:

\begin{center}
\begin{tabular}{|r|c|c|}
\hline
\multicolumn{3}{|c|}{$c=3.25$}\\
\hline
 ohne Housekeeping &relative Genauigkeit & absolute Genauigkeit \\
 \hline
 \hline
 Anzahl Polishs & -& -\\
 Präzision (Bits) & 7440 & 7440 \\
 CPU-Zeit & 0.120s & 0.118s\\
 \hline
\end{tabular}
\end{center}

Die Ergenisse werden erheblich schneller berechnet, allerdings auf Kosten der benötigten Bits für die Zahlendarstellung. Da hier kein Polieren geschieht, wird auch kein Taylormodell als solches initialisiert, das heißt, es werden keine Fehlersymbole eingesetzt und rein auf der Ebene der reellen Zahlen der \verb+iRRAM+ gerechnet.

Für $c=3.75$, einem Wert, bei dem die Funktion chaotisches Verhalten aufweist und zwischen vielen Werten hin- und herspringt, ist erkennbar, dass ein Rechnen mit diesen Housekeeping-Parametern und absoluter Genauigkeit nicht praktikabel ist, da die Berechnung bereits nach 64 Iterationen eine Laufzeit von über 15 Sekunden hat, welche scheinbar exponentiell steigt:

\begin{center}
\begin{tabular}{|r|c|c|}
\hline
\multicolumn{3}{|c|}{$c=3.75$}\\
\hline
 mit Housekeeping &relative Genauigkeit & absolute Genauigkeit \\
 \hline
 \hline
 Anzahl Polishs & 5511 & ?\\
 Präzision (Bits) & 7440 & ?\\
 CPU-Zeit & 4.02s & >60s\\
 \hline
\end{tabular}
\end{center}

Wie oben zeigt sich zwischen relativer und absoluter Genauigkeit bei der Verwendung ohne Housekeeping-Methoden kein nennenswerter Unterschied. Zudem scheint bei der hier verwendeten Konfiguration lediglich ein Berechnungsoverhead zu entstehen, welcher keine Auswirkungen auf die Qualität des Ergebnisses hat.


\begin{center}
\begin{tabular}{|r|c|c|}
\hline
\multicolumn{3}{|c|}{$c=3.75$}\\
\hline
 ohne Housekeeping &relative Genauigkeit & absolute Genauigkeit \\
 \hline
 \hline
 Anzahl Polishs & - & -\\
 Präzision (Bits) & 7440 & 7440\\
 CPU-Zeit & 0.12s & 0.12s\\
 \hline
\end{tabular}
\end{center}


Insgesamt lässt sich beobachten, dass die Berechnung der Interationen mit relativer Genauigkeit die besten Ergebnisse liefert, weshalb diese im Folgenden zugrunde liegt.

\section{Housekeeping}

% 
% \begin{table}[ht]
%     \centering
%     \def\arraystretch{1.3}
%     \begin{tabular}{r|c|c|c}
%     Iterationen &Metrik & absolut & relativ \\
%     \hline
%     $n=60$ & CPU-Zeit & $0.08s$ &  $3.21s$       \\
%            & Genauigkeit & \verb+double+ &   $2^{-748}$      \\
%            & Anzahl Polishs & 45 &    374     \\ 
%     \hline
%     $n=65$ & CPU-Zeit & $0.14s$ &  $18.06s$       \\
%            & Genauigkeit & \verb+double+ &  $2^{-748}$       \\
%            & Anzahl Polishs & 71 &   409      \\
%     \hline
%     $n=66$ & CPU-Zeit & $0.18s$ & $69s$\\
%            & Genauigkeit & \verb+double+ &   $2^{-748}$      \\
%            & Anzahl Polishs & 77 &    416     \\
%     \hline
%     $n=67$ & CPU-Zeit & $0.23s$ & $180s$ \\
%            & Genauigkeit & \verb+double+ &   $2^{-748}$      \\
%            & Anzahl Polishs & 84 &     423    \\
%     \hline
%     $n=100$ & CPU-Zeit & $0.38s$ & $>180s$ \\
%            & Genauigkeit & $2^{-748}$ &??\\
%            & Anzahl Polishs & 314 &??\\
%     \hline
%     $n=500$ & CPU-Zeit & $2.83s$ &$>180s$\\
%            & Genauigkeit & $2^{-2876}$ &??\\
%            & Anzahl Polishs & 3939 &??\\
%     \end{tabular}
%     \caption[Vergleich von Genauigkeitsmodellen]{Vergleich vom Rechnen mit absoluter und relativer Genauigkeit}
%     \label{tab:precision}
% \end{table}
